# configs/experiment/exp_001_concordance.yaml
defaults:
  - _self_
  - /data: h3k27me3_200bp
  - /model: nb_mu_r_small

# Main training parameters - moved to top level
num_epochs: 100
learning_rate: 0.001
weight_decay: 0.01
patience: 10
device: "cuda:0"
# Name of the loss function to use
loss_fn: "replicate_concordance_mse"

# Data parameters - moved to top level
name: "h3k27me3"
batch_size: 8192

# Name for this run group in W&B
wandb:
  group: "refactored_runs"
  project: "chipvi"

# Scheduler configuration
scheduler:
  warmup_epochs: 2
  scheduler_type: cosine
  total_epochs: ${num_epochs}

# Early stopping configuration  
early_stopping:
  patience: 10
  monitor: val_loss
  mode: min

# Gradient clipping configuration
gradient_clipping:
  max_norm: 1.0

# Checkpointing strategies configuration
checkpointing:
  strategies:
    - metric: val_loss
      mode: min
      filename: best_loss.pt
      overwrite: true
    - metric: val_residual_spearman
      mode: max
      filename: best_corr.pt
      overwrite: true